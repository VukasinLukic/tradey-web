ğŸ“„ DOKUMENT 3: AI ARCHITECTURE & STRATEGY

Ovde Ä‡e biti NAJTEHNIÄŒKI deo - ali i dalje bez koda, samo plan.



ğŸ§  KOJE AI MODELE KORISTIÅ  (i zaÅ¡to)

MODEL 1: CLIP (OpenAI) - za image embeddings

Å ta je CLIP?

Model koji "razume" slike i tekst u istom prostoru

Pre-trained na 400M slika

NE TRENIRAÅ  GA - samo koristiÅ¡

Verzija: openai/clip-vit-base-patch32

Å ta radi:

Slika jakne â†’ CLIP â†’ vektor [512 brojeva]

ZaÅ¡to baÅ¡ CLIP?

âœ… Razume modu i stil

âœ… Brz (300ms per image na CPU)

âœ… MoÅ¾e da radi bez GPU-a

âœ… Besplatan i open source

Alternativa (ako imaÅ¡ GPU):

openai/clip-vit-large-patch14 (bolji, ali sporiji)



MODEL 2: Sentence Transformers - za text embeddings

Verzija: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

Å ta radi:

"Top koÅ¾na jakna..." â†’ Transformer â†’ vektor [384 brojeva]

ZaÅ¡to baÅ¡ ovaj?

âœ… PodrÅ¾ava srpski jezik

âœ… Brz (50ms per text na CPU)

âœ… Mali model (120MB)



MODEL 3: Custom Ranking Model (tvoj algoritam)

OVO NEÄ†EÅ  TRENIRATI!

Umesto treniranja, koristiÅ¡ weighted scoring:

python

final_score = (

    0.40 * cosine_similarity(user_style_vector, item_image_embedding) +

    0.30 * size_match_score +

    0.15 * popularity_score +

    0.10 * price_match_score +

    0.05 * location_score

)

```



**Kasnije (kada imaÅ¡ podatke):**

- MoÅ¾eÅ¡ da trenaÅ¡ **ranking model** (LightGBM ili XGBoost)

- Ulaz: features (similarity, popularity...)

- Izlaz: verovatnoÄ‡a da Ä‡e korisnik lajkovati



---



### MODEL 4: GPT-2 / Llama - za generisanje opisa



**Verzija:** `gpt2` ili Claude API (Å¡to veÄ‡ koristiÅ¡)



**Å ta radi:**

```

Input: {category: "jakna", color: "black", condition: "kao_novo"}

Output: "Top koÅ¾na jakna, bukvalno kao nova ğŸ–¤ Nosila 2x max."

```



**MVP pristup:**

- Koristi **template-based** generaciju (jeftinije)

- Kasnije ukljuÄi LLM (Claude API)



---



## ğŸ—ï¸ ARHITEKTURA AI SERVERA (detaljan plan)



### FOLDER STRUKTURA

```

tradey-ai-server/

â”œâ”€â”€ app/

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ main.py                 # FastAPI app

â”‚   â”œâ”€â”€ config.py               # Config (model paths, Firebase...)

â”‚   â”‚

â”‚   â”œâ”€â”€ api/

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ process_item.py     # POST /api/process-item

â”‚   â”‚   â”œâ”€â”€ recommend.py        # POST /api/recommend

â”‚   â”‚   â”œâ”€â”€ similar.py          # POST /api/similar-items

â”‚   â”‚   â”œâ”€â”€ description.py      # POST /api/generate-description

â”‚   â”‚   â””â”€â”€ update_profile.py   # POST /api/update-profile

â”‚   â”‚

â”‚   â”œâ”€â”€ ml/

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ embeddings.py       # CLIP + Sentence Transformers

â”‚   â”‚   â”œâ”€â”€ ranking.py          # Scoring logic

â”‚   â”‚   â”œâ”€â”€ cold_start.py       # Cold start strategy

â”‚   â”‚   â””â”€â”€ style_detector.py   # Boja, stil, brend detection

â”‚   â”‚

â”‚   â”œâ”€â”€ db/

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”œâ”€â”€ vector_store.py     # Qdrant / FAISS wrapper

â”‚   â”‚   â””â”€â”€ firebase_client.py  # Firebase connection

â”‚   â”‚

â”‚   â””â”€â”€ utils/

â”‚       â”œâ”€â”€ __init__.py

â”‚       â”œâ”€â”€ image_utils.py      # Download, resize...

â”‚       â””â”€â”€ text_utils.py       # Text cleaning

â”‚

â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ embeddings.db           # SQLite (metadata)

â”‚   â”œâ”€â”€ vectors/                # FAISS index files

â”‚   â””â”€â”€ user_profiles.json      # Cached user vectors

â”‚

â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ clip/                   # Downloaded CLIP model

â”‚   â”œâ”€â”€ sentence-transformer/   # Downloaded ST model

â”‚   â””â”€â”€ ...

â”‚

â”œâ”€â”€ tests/

â”‚   â”œâ”€â”€ test_embeddings.py

â”‚   â””â”€â”€ test_ranking.py

â”‚

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ Dockerfile                  # Za kasnije

â””â”€â”€ README.md



ğŸ”§ TEHNIÄŒKI STACK

python

# requirements.txt



# Core framework

fastapi==0.104.1

uvicorn[standard]==0.24.0

pydantic==2.5.0



# ML models

torch==2.1.0                    # PyTorch (CPU version)

transformers==4.35.0            # HuggingFace

sentence-transformers==2.2.2

Pillow==10.1.0                  # Image processing



# Vector database

qdrant-client==1.7.0            # Production choice

# OR faiss-cpu==1.7.4           # Lighter alternative



# Firebase

firebase-admin==6.2.0



# Utils

requests==2.31.0

numpy==1.24.3

pandas==2.1.3                   # Za batch processing

python-dotenv==1.0.0



# Development

pytest==7.4.3



ğŸš€ KAKO RADE EMBEDDINGS (najvaÅ¾niji deo)

KORAK 1: Generisanje embeddings (kad se postavi item)

python

# Pseudokod



def process_new_item(item_id, image_url, category):

    

    # 1. Preuzmi sliku

    image = download_image(image_url)

    

    # 2. GeneriÅ¡i image embedding

    image_embedding = CLIP.encode_image(image)  

    # â†’ numpy array [512 floats]

    

    # 3. Detektuj boju, stil, brend

    detected_color = detect_color(image)

    detected_style = detect_style(image_embedding)

    detected_brand = detect_brand(image)  # OCR + logo detection

    

    # 4. GeneriÅ¡i opis (ako korisnik nije dao)

    description = generate_description(

        category=category,

        color=detected_color,

        style=detected_style,

        brand=detected_brand

    )

    

    # 5. GeneriÅ¡i text embedding od opisa

    text_embedding = SentenceTransformer.encode(description)

    # â†’ numpy array [384 floats]

    

    # 6. SkladiÅ¡ti u vector DB

    VectorStore.add(

        item_id=item_id,

        image_vector=image_embedding,

        text_vector=text_embedding,

        metadata={

            "category": category,

            "color": detected_color,

            "style": detected_style,

            "brand": detected_brand

        }

    )

    

    # 7. Update Firebase (aiGenerated fields)

    Firebase.update_item(item_id, {

        "aiGenerated": {

            "description": description,

            "detectedBrand": detected_brand,

            "detectedColor": detected_color,

            "detectedStyle": detected_style

        }

    })

    

    return success



KORAK 2: User style vector (kako AI uÄi korisnika)

python

# Pseudokod



def compute_user_style_vector(user_id):

    

    # 1. Uzmi sve swipe right interakcije

    liked_items = Firebase.get_user_likes(user_id)

    

    # 2. Uzmi embeddings tih itema

    liked_embeddings = []

    for item_id in liked_items:

        embedding = VectorStore.get_embedding(item_id)

        liked_embeddings.append(embedding)

    

    # 3. ProseÄni vektor = user style

    user_style_vector = np.mean(liked_embeddings, axis=0)

    # â†’ numpy array [512 floats]

    

    # 4. KeÅ¡iraj za brÅ¾e preporuke

    cache_user_profile(user_id, user_style_vector)

    

    return user_style_vector

```



**Primer (vizuelno):**

```

Marija lajkovala:

  - Crna jakna   â†’ embedding [0.1, 0.8, -0.3, ...]

  - Crne pantalone â†’ embedding [0.2, 0.7, -0.2, ...]

  - Bela majica  â†’ embedding [-0.5, 0.3, 0.8, ...]



Njen style vector = prosek:

  â†’ [-0.07, 0.6, 0.1, ...]



AI sada zna: "Marija voli casual, crno-bele kombinacije"



KORAK 3: Personalizovani feed (kako AI rangira)

python

# Pseudokod



def generate_personalized_feed(user_id, count=50):

    

    # 1. Uzmi user preferences

    user = Firebase.get_user(user_id)

    user_style_vector = get_cached_user_profile(user_id)

    

    # 2. Hard filter (size, gender, location)

    candidate_items = Firebase.query_items({

        "size": {"in": user.preferences.sizes},

        "gender": {"in": user.preferences.interestedIn},

        "location": user.profile.city,  # opciono

        "status": "active"

    })

    

    # 3. Uzmi embeddings svih kandidata

    candidate_embeddings = VectorStore.get_batch(candidate_items)

    

    # 4. RaÄunaj similarity score

    similarity_scores = []

    for item_id, item_embedding in candidate_embeddings:

        

        # Cosine similarity

        similarity = cosine_similarity(

            user_style_vector, 

            item_embedding

        )

        

        similarity_scores.append({

            "itemId": item_id,

            "styleSimilarity": similarity

        })

    

    # 5. Dodaj ostale faktore

    final_scores = []

    for item in similarity_scores:

        

        item_data = Firebase.get_item(item.itemId)

        

        # Style score (40%)

        style_score = item.styleSimilarity * 0.40

        

        # Size exact match (30%)

        size_score = 0.30 if item_data.size == user.size else 0.15

        

        # Popularity (15%)

        max_likes = 100  # normalizacija

        popularity_score = (item_data.stats.totalLikes / max_likes) * 0.15

        

        # Budget (10%)

        budget_score = 0.10 if item_data.price <= user.budgetMax else 0

        

        # Location (5%)

        location_score = 0.05 if item_data.location == user.city else 0

        

        final_score = (

            style_score + 

            size_score + 

            popularity_score + 

            budget_score + 

            location_score

        )

        

        final_scores.append({

            "itemId": item.itemId,

            "score": final_score

        })

    

    # 6. Sortiraj po score-u

    ranked = sorted(final_scores, key=lambda x: x.score, reverse=True)

    

    # 7. Diverzitet (90% safe + 10% exploration)

    safe_items = ranked[:45]  # top 90%

    exploration_items = random.sample(ranked[45:], 5)  # random 10%

    

    final_feed = safe_items + exploration_items

    random.shuffle(final_feed)  # Shuffle da ne bude predvidljivo

    

    return final_feed[:count]



KORAK 4: Cold Start (novi korisnik)

python

# Pseudokod



def generate_cold_start_feed(user_id):

    

    user = Firebase.get_user(user_id)

    total_swipes = user.stats.totalSwipes

    

    # FAZA 1: 0-10 swipe-ova

    if total_swipes < 10:

        return get_popular_items_from_quiz(user.preferences.styles)

    

    # FAZA 2: 10-30 swipe-ova

    elif total_swipes < 30:

        quiz_items = get_popular_items_from_quiz(user.preferences.styles)

        behavioral_items = get_items_from_early_likes(user_id)

        

        return mix(quiz_items * 0.7, behavioral_items * 0.3)

    

    # FAZA 3: 30+ swipe-ova

    else:

        return generate_personalized_feed(user_id)



ğŸ—„ï¸ VECTOR DATABASE (Qdrant vs FAISS)

OPCIJA 1: FAISS (jednostavnije za MVP)

Prednosti:

âœ… Radi in-memory (brzo)

âœ… Jednostavan setup

âœ… Besplatan

Mane:

âŒ Nema persistence (mora da se reload-uje)

âŒ Nema metadata filtriranje

Setup:

python

import faiss

import numpy as np



# Inicijalizuj index

dimension = 512  # CLIP embedding size

index = faiss.IndexFlatL2(dimension)  # L2 distance



# Dodaj vektore

embeddings = np.array([...])  # shape: (N, 512)

index.add(embeddings)



# Pretraga

query_vector = np.array([...])  # shape: (1, 512)

distances, indices = index.search(query_vector, k=50)



OPCIJA 2: Qdrant (bolje za produkciju)

Prednosti:

âœ… Persistence (ne gubi podatke)

âœ… Metadata filtriranje

âœ… REST API

âœ… Skalabilno

Mane:

âŒ Malo kompleksnije

Setup:

python

from qdrant_client import QdrantClient

from qdrant_client.models import Distance, VectorParams, PointStruct



# Inicijalizuj client

client = QdrantClient(path="./data/qdrant")  # lokalno



# Kreiraj collection

client.create_collection(

    collection_name="tradey_items",

    vectors_config=VectorParams(size=512, distance=Distance.COSINE)

)



# Dodaj vektor

client.upsert(

    collection_name="tradey_items",

    points=[

        PointStruct(

            id="item_xyz789",

            vector=[0.1, 0.2, ...],  # 512 dims

            payload={

                "category": "jakna",

                "color": "black",

                "size": "M"

            }

        )

    ]

)



# Pretraga sa filterima

results = client.search(

    collection_name="tradey_items",

    query_vector=[0.1, 0.2, ...],

    limit=50,

    query_filter={

        "must": [

            {"key": "size", "match": {"value": "M"}}

        ]

    }

)

ğŸ’¡ PREPORUKA: PoÄni sa FAISS (brÅ¾i start), kasnije prelazi na Qdrant.



ğŸ“Š PERFORMANSE (realnost)

Koliko je brzo?

Na CPU serveru (bez GPU):

Operacija

Vreme

Å ta radi

CLIP embedding (1 slika)

~300ms

GeneriÅ¡e vektor od slike

Text embedding (1 opis)

~50ms

GeneriÅ¡e vektor od teksta

Vector search (50k itema)

~100ms

Pronalazi najsliÄnije

Total za 1 item

~450ms

Process new item

Total za feed

~200ms

Recommend 50 items

Na GPU serveru (ako imaÅ¡):

CLIP: ~50ms (6x brÅ¾e)

Ostalo: isto

ZakljuÄak: CPU je dovoljan za 10k korisnika.



ğŸ” SIGURNOST & API KEYS

Environment Variables (.env)

bash

# Firebase

FIREBASE_CREDENTIALS_PATH=/path/to/firebase-key.json



# Server

AI_SERVER_PORT=8000

AI_SERVER_HOST=0.0.0.0



# API Keys (ako treba)

CLAUDE_API_KEY=sk-ant-...  # za generisanje opisa



# Vector DB

QDRANT_PATH=./data/qdrant



# Models

CLIP_MODEL=openai/clip-vit-base-patch32

SENTENCE_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2



ğŸ–¥ï¸ KAKO PODIGNEÅ  AI SERVER (step-by-step)

FAZA 1: PRIPREMA SERVERA

Korak 1: SSH u server

bash

ssh root@Ñ‚Ğ²Ğ¾Ñ˜-IP

Korak 2: Update sistema

bash

# Ubuntu/Debian

sudo apt update && sudo apt upgrade -y



# Install Python 3.10+

sudo apt install python3.10 python3.10-venv python3-pip -y



# Install dodatke

sudo apt install git curl wget -y

Korak 3: Kreiraj folder projekta

bash

mkdir /opt/tradey-ai

cd /opt/tradey-ai



FAZA 2: SETUP PYTHON OKRUÅ½ENJA

Korak 4: Virtual environment

bash

python3 -m venv venv

source venv/bin/activate

Korak 5: Install dependencies

bash

# Kreiraj requirements.txt (kopiraj sa gore)

nano requirements.txt



# Install

pip install --upgrade pip

pip install -r requirements.txt

â³ Ovo Ä‡e trajati 10-15 minuta (PyTorch je veliki)



FAZA 3: DOWNLOAD MODELA

Korak 6: Download CLIP

bash

python3 << EOF

from transformers import CLIPModel, CLIPProcessor



model_name = "openai/clip-vit-base-patch32"

model = CLIPModel.from_pretrained(model_name)

processor = CLIPProcessor.from_pretrained(model_name)



model.save_pretrained("./models/clip")

processor.save_pretrained("./models/clip")

print("CLIP downloaded!")

EOF

Korak 7: Download Sentence Transformer

bash

python3 << EOF

from sentence_transformers import SentenceTransformer



model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

model = SentenceTransformer(model_name)

model.save("./models/sentence-transformer")

print("SentenceTransformer downloaded!")

EOF

Sada imaÅ¡ modele lokalno - ne treba internet za inference.



FAZA 4: SETUP FIREBASEA

Korak 8: Firebase credentials

bash

# Upload Firebase JSON key na server

scp /path/to/firebase-key.json root@IP:/opt/tradey-ai/firebase-key.json

Korak 9: .env file

bash

nano .env



# Dodaj:

FIREBASE_CREDENTIALS_PATH=/opt/tradey-ai/firebase-key.json

AI_SERVER_PORT=8000

QDRANT_PATH=./data/qdrant



FAZA 5: POKRENI SERVER

Korak 10: Run FastAPI

bash

# Development mode

uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

Testiranje:

bash

curl http://localhost:8000/health

# â†’ {"status": "ok"}



Korak 11: Production mode (systemd service)

bash

sudo nano /etc/systemd/system/tradey-ai.service

Dodaj:

ini

[Unit]

Description=Tradey AI Server

After=network.target



[Service]

Type=simple

User=root

WorkingDirectory=/opt/tradey-ai

Environment="PATH=/opt/tradey-ai/venv/bin"

ExecStart=/opt/tradey-ai/venv/bin/uvicorn app.main:app --host 0.0.0.0 --port 8000

Restart=always



[Install]

WantedBy=multi-user.target

Enable i start:

bash

sudo systemctl daemon-reload

sudo systemctl enable tradey-ai

sudo systemctl start tradey-ai

sudo systemctl status tradey-ai



Korak 12: Firewall & nginx (opciono)

bash

# Firewall

sudo ufw allow 8000/tcp



# Nginx reverse proxy (ako Å¾eliÅ¡ HTTPS)

sudo apt install nginx -y



FAZA 6: TESTIRANJE

Korak 13: Test endpoint

bash

curl -X POST http://tvoj-IP:8000/api/process-item \

  -H "Content-Type: application/json" \

  -d '{

    "itemId": "test_001",

    "imageUrl": "https://example.com/jakna.jpg",

    "category": "jakna"

  }'



ğŸ“Œ FINAL CHECKLIST

Kada sve radi:

âœ… Python 3.10+ instaliran âœ… Virtual env kreiran âœ… Dependencies instalirani âœ… CLIP i SentenceTransformer downloadovani âœ… Firebase credentials setupovani âœ… FastAPI server radi âœ… Systemd service enabled âœ… Firewall otvoren



